{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.cElementTree as ET\n",
    "import os\n",
    "import nltk\n",
    "import string\n",
    "import random\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from pandas import DataFrame\n",
    "import nltk.data\n",
    "from nltk import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Training Files for Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set to the appropriate folder on your local drive\n",
    "wd = os.path.dirname(os.path.abspath('__file__'))\n",
    "folders = [\"\\\\Dataset\\\\training-RiskFactors-Complete-Set1\\\\\", \"\\\\Dataset\\\\training-RiskFactors-Complete-Set2\\\\\"]\n",
    "\n",
    "#datafolder.append(codefolder.replace(\"Code\", \"Dataset\\\\training-RiskFactors-Complete-Set1\"))\n",
    "#datafolder.append(codefolder.replace(\"Code\", \"Dataset\\\\training-RiskFactors-Complete-Set2\"))\n",
    "\n",
    "#print (datafolder)\n",
    "\n",
    "filenames = []\n",
    "\n",
    "for folder in folders:\n",
    "    for file in os.listdir(str(wd)+folder):\n",
    "        filename = os.fsdecode(os.fsencode((str(wd)+folder+file)))\n",
    "        if filename.endswith( ('.xml') ): # select xml files\n",
    "            #print(filename)\n",
    "            filenames.append(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are in total, 790 files as part of the training set. \n"
     ]
    }
   ],
   "source": [
    "print(\"There are in total, {} files as part of the training set. \".format(len(filenames)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Testing specific files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 514 test XML files for validating the model.\n"
     ]
    }
   ],
   "source": [
    "# set to the appropriate folder on your local drive\n",
    "wd = os.path.dirname(os.path.abspath('__file__'))\n",
    "datafolder = [\"\\\\Dataset\\\\testing-RiskFactors-Complete\\\\\"]\n",
    "#print (datafolder)\n",
    "\n",
    "testfilenames = []\n",
    "\n",
    "for folder in datafolder:\n",
    "    for file in os.listdir(str(wd)+folder):\n",
    "        filename = os.fsdecode(os.fsencode((str(wd)+folder+file)))\n",
    "        if filename.endswith( ('.xml') ): # select xml files\n",
    "            #print(filename)\n",
    "            testfilenames.append(filename)\n",
    "            \n",
    "print(\"There are {} test XML files for validating the model.\".format(len(testfilenames)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define function to get sentences and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentences(file):\n",
    "\n",
    "    tree = ET.ElementTree(file=file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    text = root.find('TEXT').text\n",
    "    sentences = [sent.split('\\n') for sent in sent_tokenize(text) if sent!='\\n']\n",
    "    all_sentences = []\n",
    "\n",
    "    for item in sentences:\n",
    "        for sub_item in item:\n",
    "            if sub_item.replace(' ','') != '':\n",
    "                all_sentences.append(sub_item)    \n",
    "    \n",
    "    return all_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function definition for processing a file\n",
    "\n",
    "This takes in the filename, tag and attribute as inputs and generates sentences and the corresponding label to form the dataset for training the model.  The function 'get_sentences' is incorporated into the function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(file, tag, attribute):\n",
    "    \n",
    "    # get all sentences in the file\n",
    "    tree = ET.ElementTree(file=file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    text = root.find('TEXT').text\n",
    "    sentences = [sent.split('\\n') for sent in sent_tokenize(text) if sent!='\\n']\n",
    "    all_sentences = []\n",
    "\n",
    "    for item in sentences:\n",
    "        for sub_item in item:\n",
    "            if sub_item.replace(' ','') != '':\n",
    "                all_sentences.append(sub_item)    \n",
    "                \n",
    "    #all_sent = get_sentences(file)\n",
    "    sent_label = {}\n",
    "\n",
    "    sub_tags = []\n",
    "    for item in root.find(\"TAGS\"):\n",
    "        if item.tag  == tag:\n",
    "            label = (item.tag + \".\" + item.attrib[attribute]).lower().replace(\" \", \"_\")\n",
    "        else:\n",
    "            label = \"\"\n",
    "\n",
    "        for sub_item in item.findall(item.tag):\n",
    "            if (item.tag==tag) and ('text' in sub_item.attrib.keys()):\n",
    "                sub_tags.append((sub_item.attrib['text'], sub_item.attrib[attribute]))\n",
    "\n",
    "\n",
    "    count=0\n",
    "    for sent in all_sentences:\n",
    "        label='Other'\n",
    "        for tag in set(sub_tags):\n",
    "            if tag[0] in sent:\n",
    "                label = tag[1]\n",
    "                count += 1\n",
    "\n",
    "        sent_label[sent] = label\n",
    "        \n",
    "    # return empty dict if no tag found in file\n",
    "    # else, return the sentences with the labels\n",
    "    if count==0:\n",
    "        return {}\n",
    "    else:\n",
    "        return sent_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_TrainingData(tag, attrib, filenames, pct_split=0.9):\n",
    "\n",
    "    \"\"\"\n",
    "    All files in the list (which holds the list of files in the directory) are parsed\n",
    "    through to generate the training / dev datasets for the tag/attribute in context.\n",
    "    \n",
    "    The tags and attributes are passed on to the function as parameters.\n",
    "    \n",
    "    Input: \n",
    "    filenames: names of the file to be read in for processing in a list object\n",
    "    tag: tag, as identified in the annotation.  Ex: DIABETES, HYPERTENSION etc. (string)\n",
    "    attribute: specific attribute within the tag, from which to extract the value from (string)\n",
    "    \n",
    "    Returns: \n",
    "    Dataframe of the train / dev datasets (for the tag/attribute)\n",
    "    \"\"\"\n",
    "    \n",
    "    # using a 90/10 split by default unless specified as parameter\n",
    "    split_index = int(len(filenames)*pct_split)\n",
    "    random.seed(42)\n",
    "    random.shuffle(filenames)\n",
    "    \n",
    "    train_files=[]\n",
    "    dev_files=[]\n",
    "    train_sent = []\n",
    "    train_labels = []\n",
    "    dev_sent = []\n",
    "    dev_labels = []\n",
    "\n",
    "    for file in filenames[:split_index]:\n",
    "        file_data = process_file(file=file, tag=tag, attribute=attrib)\n",
    "        for i in range(0, len(file_data)):\n",
    "            train_files.append(file)\n",
    "            \n",
    "        for key, value in file_data.items():\n",
    "            train_sent.append(key)\n",
    "            train_labels.append(value)\n",
    "        \n",
    "    for file in filenames[split_index:]:\n",
    "        file_data = process_file(file=file, tag=tag, attribute=attrib)\n",
    "        for i in range(0, len(file_data)):\n",
    "            dev_files.append(file)\n",
    "        \n",
    "        for key, value in file_data.items():\n",
    "            dev_sent.append(key)\n",
    "            dev_labels.append(value)\n",
    "\n",
    "    train_df = pd.DataFrame({'filename': train_files, 'sentence': train_sent, 'label': train_labels})\n",
    "    dev_df = pd.DataFrame({'filename': dev_files, 'sentence': dev_sent, 'label': dev_labels})\n",
    "    return train_df, dev_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_TestData(tag, attrib, filenames):\n",
    "\n",
    "    \"\"\"\n",
    "    All files in the list (which holds the list of files in the directory) are parsed\n",
    "    through to generate the test datasets for the tag/attribute in context.\n",
    "    \n",
    "    The tags and attributes are passed on to the function as parameters.\n",
    "    \n",
    "    Input: \n",
    "    filenames: names of the file to be read in for processing in a list object\n",
    "    tag: tag, as identified in the annotation.  Ex: DIABETES, HYPERTENSION etc. (string)\n",
    "    attribute: specific attribute within the tag, from which to extract the value from (string)\n",
    "    \n",
    "    Returns: \n",
    "    Dataframe of the test dataset (for the tag/attribute)\n",
    "    \"\"\"\n",
    "    \n",
    "    test_files=[]\n",
    "    test_sent = []\n",
    "    test_labels = []\n",
    "\n",
    "    for file in filenames:\n",
    "        file_data = process_file(file=file, tag=tag, attribute=attrib)\n",
    "        for i in range(0, len(file_data)):\n",
    "            test_files.append(file)\n",
    "            \n",
    "        for key, value in file_data.items():\n",
    "            test_sent.append(key)\n",
    "            test_labels.append(value)\n",
    "        \n",
    "    test_df = pd.DataFrame({'filename': test_files, 'sentence': test_sent, 'label': test_labels})\n",
    "    return test_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filename(fullpath):\n",
    "    #print(fullpath)\n",
    "    fullpath=fullpath.replace(\"C:\\\\Users\\\\sudha\\\\Documents\\\\W266-NLP\\\\Final-Project-W266\\\\Code\\\\Dataset\\\\training-RiskFactors-Complete-Set1\\\\\", \"\")\n",
    "    return fullpath.replace(\"C:\\\\Users\\\\sudha\\\\Documents\\\\W266-NLP\\\\Final-Project-W266\\\\Code\\\\Dataset\\\\training-RiskFactors-Complete-Set2\\\\\", \"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_testfilename(fullpath):\n",
    "    return fullpath.replace(\"C:\\\\Users\\\\sudha\\\\Documents\\\\W266-NLP\\\\Final-Project-W266\\\\Code\\\\Dataset\\\\testing-RiskFactors-Complete\\\\\", \"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Data for Models\n",
    "\n",
    "The goal is to generate the tokens and the corresponding labels specific to model of interest.  Below, we will be building the data for 'indicator' attribute for the following tags:\n",
    "\n",
    "* DIABETES\n",
    "* CAD\n",
    "* HYPERTENSION\n",
    "* HYPERLIPIDEMIA\n",
    "* OBESE\n",
    "* FAMILY_HIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update the tag / indicator to get the training / dev / test datasets for them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data for model #2\n",
    "tag = 'DIABETES'\n",
    "attribute = 'indicator'\n",
    "\n",
    "# training & dev datasets\n",
    "df_train, df_dev = get_TrainingData(tag, attribute, filenames)\n",
    "df_train['file'] = df_train['filename'].apply(get_filename)\n",
    "df_train.drop('filename', 1, inplace=True)\n",
    "\n",
    "df_dev['file'] = df_dev['filename'].apply(get_filename)\n",
    "df_dev.drop('filename', 1, inplace=True)\n",
    "\n",
    "# test dataset\n",
    "df_test = get_TestData(tag, attribute, testfilenames)\n",
    "df_test['file'] = df_test['filename'].apply(get_testfilename)\n",
    "df_test.drop('filename', 1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Record date: 2080-02-18</td>\n",
       "      <td>Other</td>\n",
       "      <td>110-03.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SDU JAR Admission Note</td>\n",
       "      <td>Other</td>\n",
       "      <td>110-03.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Name: \\t Yosef Villegas</td>\n",
       "      <td>Other</td>\n",
       "      <td>110-03.xml</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  sentence  label        file\n",
       "0  Record date: 2080-02-18  Other  110-03.xml\n",
       "1   SDU JAR Admission Note  Other  110-03.xml\n",
       "2  Name: \\t Yosef Villegas  Other  110-03.xml"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Record date: 2072-12-04</td>\n",
       "      <td>Other</td>\n",
       "      <td>284-04.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HPI: 81 y.o.w.</td>\n",
       "      <td>Other</td>\n",
       "      <td>284-04.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>with multiple medical problems including DM, H...</td>\n",
       "      <td>mention</td>\n",
       "      <td>284-04.xml</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence    label        file\n",
       "0                            Record date: 2072-12-04    Other  284-04.xml\n",
       "1                                     HPI: 81 y.o.w.    Other  284-04.xml\n",
       "2  with multiple medical problems including DM, H...  mention  284-04.xml"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Record date: 2097-03-25</td>\n",
       "      <td>Other</td>\n",
       "      <td>270-02.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Patient Name: Whitaker, Vincent</td>\n",
       "      <td>Other</td>\n",
       "      <td>270-02.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MRN: 29964344</td>\n",
       "      <td>Other</td>\n",
       "      <td>270-02.xml</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          sentence  label        file\n",
       "0          Record date: 2097-03-25  Other  270-02.xml\n",
       "1  Patient Name: Whitaker, Vincent  Other  270-02.xml\n",
       "2                    MRN: 29964344  Other  270-02.xml"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47888, 3)\n",
      "(4482, 3)\n",
      "(35556, 3)\n"
     ]
    }
   ],
   "source": [
    "# check size of each of the datasets generated\n",
    "print(df_train.shape)\n",
    "print(df_dev.shape)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write the TRAINING & DEV Datasets\n",
    "\n",
    "Capture the TRAINING and DEV datasets for the tag/attribute in context and write to the appropriate folder for processing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "\n",
    "# refer (https://blog.insightdatascience.com/using-bert-for-state-of-the-art-pre-training-for-natural-language-processing-1d87142c29e7)\n",
    "\n",
    "# get the training set for BERT in the required format\n",
    "df_train_bert = pd.DataFrame({'user_id':df_train.index,\n",
    "            'label':le.fit_transform(df_train['label']),\n",
    "            'alpha':['a']*df_train.shape[0],\n",
    "            'text':df_train['sentence'].replace(r'\\n',' ',regex=True)})\n",
    "\n",
    "\n",
    "# get the dev set for BERT in the required format\n",
    "df_dev_bert = pd.DataFrame({'user_id':df_dev.index,\n",
    "            'label':le.fit_transform(df_dev['label']),\n",
    "            'alpha':['a']*df_dev.shape[0],\n",
    "            'text':df_dev['sentence'].replace(r'\\n',' ',regex=True)})\n",
    "\n",
    "\n",
    " # Creating test dataframe according to BERT (CoLA Format)\n",
    "df_test_bert = pd.DataFrame({'id':df_test.index,\n",
    "                 'sentence':df_test['sentence'].replace(r'\\n',' ',regex=True)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get train/dev sets for BERT-NER\n",
    "\n",
    "# get the training set for BERT-NER in the required format (only token and label)\n",
    "#df_train_bert_ner = DI_train[['token', 'label']]\n",
    "#df_dev_bert_ner = DI_dev[['token', 'label']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>label</th>\n",
       "      <th>alpha</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>Record date: 2072-12-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>HPI: 81 y.o.w.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>a</td>\n",
       "      <td>with multiple medical problems including DM, H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>accompanied by her great great niece who provi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>missed few appointments - last time seen 8 mon...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  label alpha                                               text\n",
       "0        0      1     a                            Record date: 2072-12-04\n",
       "1        1      1     a                                     HPI: 81 y.o.w.\n",
       "2        2      3     a  with multiple medical problems including DM, H...\n",
       "3        3      1     a  accompanied by her great great niece who provi...\n",
       "4        4      1     a  missed few appointments - last time seen 8 mon..."
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_bert.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique labels in the training dataset:  [1 3 0 2]\n",
      "Value counts by labels (training dataset): \n",
      " 1    46581\n",
      "3     1176\n",
      "0      105\n",
      "2       26\n",
      "Name: label, dtype: int64\n",
      "\n",
      "\n",
      "Unique labels in the dev dataset:  [1 3 0 2]\n",
      "Value counts by labels (dev dataset): \n",
      " 1    4375\n",
      "3      95\n",
      "0      10\n",
      "2       2\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# set train and dev sets to be a sequential set of values\n",
    "print(\"Unique labels in the training dataset: \", df_train_bert['label'].unique())\n",
    "print(\"Value counts by labels (training dataset): \\n\", df_train_bert['label'].value_counts())\n",
    "print(\"\\n\")\n",
    "print(\"Unique labels in the dev dataset: \", df_dev_bert['label'].unique())\n",
    "print(\"Value counts by labels (dev dataset): \\n\", df_dev_bert['label'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Other      34642\n",
       "mention      779\n",
       "A1C           91\n",
       "glucose       44\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the TRAINING & DEV data to folder\n",
    "\n",
    "Write the files into appropriate folders, so that it can be uploaded to cloud for processing / building model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_path = 'data_for_bert_sent/'+tag.lower()+'_'+attribute[:3]\n",
    "\n",
    "# train / dev sets for TAG-ATTRIBUTE\n",
    "df_train_bert.to_csv(write_path+'/train.tsv', sep='\\t', index=False, header=False)\n",
    "df_dev_bert.to_csv(write_path+'/dev.tsv', sep='\\t', index=False, header=False)\n",
    "\n",
    "# test set for TAG-ATTRIBUTE\n",
    "df_test_bert.to_csv(write_path+'/test.tsv', sep='\\t', index=False, header=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check folder & Get Training\n",
    "\n",
    "The format of the datasets have been adjused so as to perform multi-class classification and predicted against the test dataset.  The dev set is used for calculating the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Other      34642\n",
       "mention      779\n",
       "A1C           91\n",
       "glucose       44\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1270</th>\n",
       "      <td>Diabetes (insulin-dependent, 3/66 HBA1C was 8.90)</td>\n",
       "      <td>mention</td>\n",
       "      <td>117-02.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1271</th>\n",
       "      <td>2.</td>\n",
       "      <td>Other</td>\n",
       "      <td>117-02.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1272</th>\n",
       "      <td>Hypercholesterolemia</td>\n",
       "      <td>Other</td>\n",
       "      <td>117-02.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1273</th>\n",
       "      <td>3.</td>\n",
       "      <td>Other</td>\n",
       "      <td>117-02.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1274</th>\n",
       "      <td>Hypertension</td>\n",
       "      <td>Other</td>\n",
       "      <td>117-02.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1275</th>\n",
       "      <td>4.</td>\n",
       "      <td>Other</td>\n",
       "      <td>117-02.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1276</th>\n",
       "      <td>History of angina</td>\n",
       "      <td>Other</td>\n",
       "      <td>117-02.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1277</th>\n",
       "      <td>5.</td>\n",
       "      <td>Other</td>\n",
       "      <td>117-02.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1278</th>\n",
       "      <td>History of cyst near scapular, upper left back</td>\n",
       "      <td>Other</td>\n",
       "      <td>117-02.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1279</th>\n",
       "      <td>6.</td>\n",
       "      <td>Other</td>\n",
       "      <td>117-02.xml</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence    label        file\n",
       "1270  Diabetes (insulin-dependent, 3/66 HBA1C was 8.90)  mention  117-02.xml\n",
       "1271                                                 2.    Other  117-02.xml\n",
       "1272                               Hypercholesterolemia    Other  117-02.xml\n",
       "1273                                                 3.    Other  117-02.xml\n",
       "1274                                       Hypertension    Other  117-02.xml\n",
       "1275                                                 4.    Other  117-02.xml\n",
       "1276                                  History of angina    Other  117-02.xml\n",
       "1277                                                 5.    Other  117-02.xml\n",
       "1278     History of cyst near scapular, upper left back    Other  117-02.xml\n",
       "1279                                                 6.    Other  117-02.xml"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[1270:1280]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
