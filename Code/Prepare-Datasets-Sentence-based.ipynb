{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.cElementTree as ET\n",
    "import os\n",
    "import nltk\n",
    "import string\n",
    "import random\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from pandas import DataFrame\n",
    "import nltk.data\n",
    "from nltk import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Training Files for Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set to the appropriate folder on your local drive\n",
    "wd = os.path.dirname(os.path.abspath('__file__'))\n",
    "folders = [\"\\\\Dataset\\\\training-RiskFactors-Complete-Set1\\\\\", \"\\\\Dataset\\\\training-RiskFactors-Complete-Set2\\\\\"]\n",
    "\n",
    "#datafolder.append(codefolder.replace(\"Code\", \"Dataset\\\\training-RiskFactors-Complete-Set1\"))\n",
    "#datafolder.append(codefolder.replace(\"Code\", \"Dataset\\\\training-RiskFactors-Complete-Set2\"))\n",
    "\n",
    "#print (datafolder)\n",
    "\n",
    "filenames = []\n",
    "\n",
    "for folder in folders:\n",
    "    for file in os.listdir(str(wd)+folder):\n",
    "        filename = os.fsdecode(os.fsencode((str(wd)+folder+file)))\n",
    "        if filename.endswith( ('.xml') ): # select xml files\n",
    "            #print(filename)\n",
    "            filenames.append(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are in total, 790 files as part of the training set. \n"
     ]
    }
   ],
   "source": [
    "print(\"There are in total, {} files as part of the training set. \".format(len(filenames)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Testing specific files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 514 test XML files for validating the model.\n"
     ]
    }
   ],
   "source": [
    "# set to the appropriate folder on your local drive\n",
    "wd = os.path.dirname(os.path.abspath('__file__'))\n",
    "datafolder = [\"\\\\Dataset\\\\testing-RiskFactors-Complete\\\\\"]\n",
    "#print (datafolder)\n",
    "\n",
    "testfilenames = []\n",
    "\n",
    "for folder in datafolder:\n",
    "    for file in os.listdir(str(wd)+folder):\n",
    "        filename = os.fsdecode(os.fsencode((str(wd)+folder+file)))\n",
    "        if filename.endswith( ('.xml') ): # select xml files\n",
    "            #print(filename)\n",
    "            testfilenames.append(filename)\n",
    "            \n",
    "print(\"There are {} test XML files for validating the model.\".format(len(testfilenames)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define function to get sentences and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentences(file):\n",
    "\n",
    "    tree = ET.ElementTree(file=file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    text = root.find('TEXT').text\n",
    "    sentences = [sent.split('\\n') for sent in sent_tokenize(text) if sent!='\\n']\n",
    "    all_sentences = []\n",
    "\n",
    "    for item in sentences:\n",
    "        for sub_item in item:\n",
    "            if sub_item.replace(' ','') != '':\n",
    "                all_sentences.append(sub_item)    \n",
    "    \n",
    "    return all_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function definition for processing a file\n",
    "\n",
    "This takes in the filename, tag and attribute as inputs and generates sentences and the corresponding label to form the dataset for training the model.  The function 'get_sentences' is incorporated into the function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(file, tag, attribute):\n",
    "    \n",
    "    # get all sentences in the file\n",
    "    tree = ET.ElementTree(file=file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    text = root.find('TEXT').text\n",
    "    sentences = [sent.split('\\n') for sent in sent_tokenize(text) if sent!='\\n']\n",
    "    all_sentences = []\n",
    "\n",
    "    for item in sentences:\n",
    "        for sub_item in item:\n",
    "            if sub_item.replace(' ','') != '':\n",
    "                all_sentences.append(sub_item)    \n",
    "                \n",
    "    #all_sent = get_sentences(file)\n",
    "    sent_label = {}\n",
    "\n",
    "    sub_tags = []\n",
    "    for item in root.find(\"TAGS\"):\n",
    "        if item.tag  == tag:\n",
    "            label = (item.tag + \".\" + item.attrib[attribute]).lower().replace(\" \", \"_\")\n",
    "        else:\n",
    "            label = \"\"\n",
    "\n",
    "        for sub_item in item.findall(item.tag):\n",
    "            if (item.tag==tag) and ('text' in sub_item.attrib.keys()):\n",
    "                sub_tags.append((sub_item.attrib['text'], sub_item.attrib[attribute]))\n",
    "\n",
    "\n",
    "    count=0\n",
    "    for sent in all_sentences:\n",
    "        label='Other'\n",
    "        for tag in set(sub_tags):\n",
    "            if tag[0] in sent:\n",
    "                label = tag[1]\n",
    "                count += 1\n",
    "\n",
    "        sent_label[sent] = label\n",
    "        \n",
    "    # return empty dict if no tag found in file\n",
    "    # else, return the sentences with the labels\n",
    "    if count==0:\n",
    "        return {}\n",
    "    else:\n",
    "        return sent_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_TrainingData(tag, attrib, filenames, pct_split=0.9):\n",
    "\n",
    "    \"\"\"\n",
    "    All files in the list (which holds the list of files in the directory) are parsed\n",
    "    through to generate the training / dev datasets for the tag/attribute in context.\n",
    "    \n",
    "    The tags and attributes are passed on to the function as parameters.\n",
    "    \n",
    "    Input: \n",
    "    filenames: names of the file to be read in for processing in a list object\n",
    "    tag: tag, as identified in the annotation.  Ex: DIABETES, HYPERTENSION etc. (string)\n",
    "    attribute: specific attribute within the tag, from which to extract the value from (string)\n",
    "    \n",
    "    Returns: \n",
    "    Dataframe of the train / dev datasets (for the tag/attribute)\n",
    "    \"\"\"\n",
    "    \n",
    "    # using a 90/10 split by default unless specified as parameter\n",
    "    split_index = int(len(filenames)*pct_split)\n",
    "    random.seed(42)\n",
    "    random.shuffle(filenames)\n",
    "    \n",
    "    train_files=[]\n",
    "    dev_files=[]\n",
    "    train_sent = []\n",
    "    train_labels = []\n",
    "    dev_sent = []\n",
    "    dev_labels = []\n",
    "\n",
    "    for file in filenames[:split_index]:\n",
    "        file_data = process_file(file=file, tag=tag, attribute=attrib)\n",
    "        for i in range(0, len(file_data)):\n",
    "            train_files.append(file)\n",
    "            \n",
    "        for key, value in file_data.items():\n",
    "            train_sent.append(key)\n",
    "            train_labels.append(value)\n",
    "        \n",
    "    for file in filenames[split_index:]:\n",
    "        file_data = process_file(file=file, tag=tag, attribute=attrib)\n",
    "        for i in range(0, len(file_data)):\n",
    "            dev_files.append(file)\n",
    "        \n",
    "        for key, value in file_data.items():\n",
    "            dev_sent.append(key)\n",
    "            dev_labels.append(value)\n",
    "\n",
    "    train_df = pd.DataFrame({'filename': train_files, 'sentence': train_sent, 'label': train_labels})\n",
    "    dev_df = pd.DataFrame({'filename': dev_files, 'sentence': dev_sent, 'label': dev_labels})\n",
    "    return train_df, dev_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_TestData(tag, attrib, filenames):\n",
    "\n",
    "    \"\"\"\n",
    "    All files in the list (which holds the list of files in the directory) are parsed\n",
    "    through to generate the test datasets for the tag/attribute in context.\n",
    "    \n",
    "    The tags and attributes are passed on to the function as parameters.\n",
    "    \n",
    "    Input: \n",
    "    filenames: names of the file to be read in for processing in a list object\n",
    "    tag: tag, as identified in the annotation.  Ex: DIABETES, HYPERTENSION etc. (string)\n",
    "    attribute: specific attribute within the tag, from which to extract the value from (string)\n",
    "    \n",
    "    Returns: \n",
    "    Dataframe of the test dataset (for the tag/attribute)\n",
    "    \"\"\"\n",
    "    \n",
    "    test_files=[]\n",
    "    test_sent = []\n",
    "    test_labels = []\n",
    "\n",
    "    for file in filenames:\n",
    "        file_data = process_file(file=file, tag=tag, attribute=attrib)\n",
    "        for i in range(0, len(file_data)):\n",
    "            test_files.append(file)\n",
    "            \n",
    "        for key, value in file_data.items():\n",
    "            test_sent.append(key)\n",
    "            test_labels.append(value)\n",
    "        \n",
    "    test_df = pd.DataFrame({'filename': test_files, 'sentence': test_sent, 'label': test_labels})\n",
    "    return test_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filename(fullpath):\n",
    "    #print(fullpath)\n",
    "    fullpath=fullpath.replace(\"C:\\\\Users\\\\sudha\\\\Documents\\\\W266-NLP\\\\Final-Project-W266\\\\Code\\\\Dataset\\\\training-RiskFactors-Complete-Set1\\\\\", \"\")\n",
    "    return fullpath.replace(\"C:\\\\Users\\\\sudha\\\\Documents\\\\W266-NLP\\\\Final-Project-W266\\\\Code\\\\Dataset\\\\training-RiskFactors-Complete-Set2\\\\\", \"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_testfilename(fullpath):\n",
    "    return fullpath.replace(\"C:\\\\Users\\\\sudha\\\\Documents\\\\W266-NLP\\\\Final-Project-W266\\\\Code\\\\Dataset\\\\testing-RiskFactors-Complete\\\\\", \"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Data for Models\n",
    "\n",
    "The goal is to generate the tokens and the corresponding labels specific to model of interest.  Below, we will be building the data for 'indicator' attribute for the following tags:\n",
    "\n",
    "* DIABETES\n",
    "* CAD\n",
    "* HYPERTENSION\n",
    "* HYPERLIPIDEMIA\n",
    "* OBESE\n",
    "* FAMILY_HIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update the tag / indicator to get the training / dev / test datasets for them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data for model #2\n",
    "tag = 'DIABETES'\n",
    "attribute = 'time'\n",
    "\n",
    "# training & dev datasets\n",
    "df_train, df_dev = get_TrainingData(tag, attribute, filenames)\n",
    "df_train['file'] = df_train['filename'].apply(get_filename)\n",
    "df_train.drop('filename', 1, inplace=True)\n",
    "\n",
    "df_dev['file'] = df_dev['filename'].apply(get_filename)\n",
    "df_dev.drop('filename', 1, inplace=True)\n",
    "\n",
    "# test dataset\n",
    "df_test = get_TestData(tag, attribute, testfilenames)\n",
    "df_test['file'] = df_test['filename'].apply(get_testfilename)\n",
    "df_test.drop('filename', 1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Record date: 2080-02-18</td>\n",
       "      <td>Other</td>\n",
       "      <td>110-03.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SDU JAR Admission Note</td>\n",
       "      <td>Other</td>\n",
       "      <td>110-03.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Name: \\t Yosef Villegas</td>\n",
       "      <td>Other</td>\n",
       "      <td>110-03.xml</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  sentence  label        file\n",
       "0  Record date: 2080-02-18  Other  110-03.xml\n",
       "1   SDU JAR Admission Note  Other  110-03.xml\n",
       "2  Name: \\t Yosef Villegas  Other  110-03.xml"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Record date: 2081-10-28</td>\n",
       "      <td>Other</td>\n",
       "      <td>157-04.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55 yo s/p admit for chest pain, PTCA and stent...</td>\n",
       "      <td>Other</td>\n",
       "      <td>157-04.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>no enzyme bump</td>\n",
       "      <td>Other</td>\n",
       "      <td>157-04.xml</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  label        file\n",
       "0                            Record date: 2081-10-28  Other  157-04.xml\n",
       "1  55 yo s/p admit for chest pain, PTCA and stent...  Other  157-04.xml\n",
       "2                                     no enzyme bump  Other  157-04.xml"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Record date: 2061-10-03</td>\n",
       "      <td>Other</td>\n",
       "      <td>304-02.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BMH Cancer Center</td>\n",
       "      <td>Other</td>\n",
       "      <td>304-02.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hematology Note</td>\n",
       "      <td>Other</td>\n",
       "      <td>304-02.xml</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  sentence  label        file\n",
       "0  Record date: 2061-10-03  Other  304-02.xml\n",
       "1        BMH Cancer Center  Other  304-02.xml\n",
       "2          Hematology Note  Other  304-02.xml"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47377, 3)\n",
      "(4993, 3)\n",
      "(35556, 3)\n"
     ]
    }
   ],
   "source": [
    "# check size of each of the datasets generated\n",
    "print(df_train.shape)\n",
    "print(df_dev.shape)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augment the data so that the minority class has good representation\n",
    "\n",
    "One of the challenges seen is due to the fact that some of the classes, such as 'glucose' in Diabetes-Indicator classification is under-represented.  In an attempt to boost the representation of the minority class, we duplicate those examples in the training set and then do a shuffle of the entire training set so that they are well spread out in the training data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_data(df, mincount=600):\n",
    "    \n",
    "    labels = df_train['label'].unique()\n",
    "    print(\"labels: \", labels)\n",
    "    print(\"\\n=============================\")\n",
    "    print(\"Value Counts before augmentation: \\n\", df['label'].value_counts())\n",
    "    print(\"\\n=============================\")\n",
    "    \n",
    "    for label in labels:\n",
    "        label_count = (df[df['label']==label]).shape[0]\n",
    "        while label_count < 600:\n",
    "            df = pd.concat([df, df[df['label']==label]], axis=0)\n",
    "            label_count = (df[df['label']==label]).shape[0]\n",
    "\n",
    "    # shuffle rows in the augmented dataset\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "    print(\"Value Counts after augmentation: \\n\", df['label'].value_counts())\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels:  ['Other' 'before DCT' 'during DCT' 'after DCT']\n",
      "\n",
      "=============================\n",
      "Value Counts before augmentation: \n",
      " Other         46098\n",
      "during DCT      680\n",
      "after DCT       301\n",
      "before DCT      298\n",
      "Name: label, dtype: int64\n",
      "\n",
      "=============================\n",
      "Value Counts after augmentation: \n",
      " Other         46098\n",
      "before DCT     1192\n",
      "during DCT      680\n",
      "after DCT       602\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_train = augment_data(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write the TRAINING & DEV Datasets\n",
    "\n",
    "Capture the TRAINING and DEV datasets for the tag/attribute in context and write to the appropriate folder for processing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "\n",
    "# refer (https://blog.insightdatascience.com/using-bert-for-state-of-the-art-pre-training-for-natural-language-processing-1d87142c29e7)\n",
    "\n",
    "# get the training set for BERT in the required format\n",
    "df_train_bert = pd.DataFrame({'user_id':df_train.index,\n",
    "            'label':le.fit_transform(df_train['label']),\n",
    "            'alpha':['a']*df_train.shape[0],\n",
    "            'text':df_train['sentence'].replace(r'\\n',' ',regex=True)})\n",
    "\n",
    "\n",
    "# get the dev set for BERT in the required format\n",
    "df_dev_bert = pd.DataFrame({'user_id':df_dev.index,\n",
    "            'label':le.fit_transform(df_dev['label']),\n",
    "            'alpha':['a']*df_dev.shape[0],\n",
    "            'text':df_dev['sentence'].replace(r'\\n',' ',regex=True)})\n",
    "\n",
    "\n",
    " # Creating test dataframe according to BERT (CoLA Format)\n",
    "df_test_bert = pd.DataFrame({'id':df_test.index,\n",
    "                 'sentence':df_test['sentence'].replace(r'\\n',' ',regex=True)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get train/dev sets for BERT-NER\n",
    "\n",
    "# get the training set for BERT-NER in the required format (only token and label)\n",
    "#df_train_bert_ner = DI_train[['token', 'label']]\n",
    "#df_dev_bert_ner = DI_dev[['token', 'label']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>label</th>\n",
       "      <th>alpha</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>Other review of systems-he has</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>No HSM, No CVA tenderness.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>MRN:\\t236-07-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>pending</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>a</td>\n",
       "      <td>diabetes mellitus.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  label alpha                             text\n",
       "0        0      0     a  Other review of systems-he has \n",
       "1        1      0     a       No HSM, No CVA tenderness.\n",
       "2        2      0     a                  MRN:\\t236-07-19\n",
       "3        3      0     a                          pending\n",
       "4        4      3     a               diabetes mellitus."
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_bert.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique labels in the training dataset:  [0 3 1 2]\n",
      "Value counts by labels (training dataset): \n",
      " 0    46098\n",
      "2     1192\n",
      "3      680\n",
      "1      602\n",
      "Name: label, dtype: int64\n",
      "\n",
      "\n",
      "Unique labels in the dev dataset:  [0 3 2 1]\n",
      "Value counts by labels (dev dataset): \n",
      " 0    4858\n",
      "3      83\n",
      "2      30\n",
      "1      22\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# set train and dev sets to be a sequential set of values\n",
    "print(\"Unique labels in the training dataset: \", df_train_bert['label'].unique())\n",
    "print(\"Value counts by labels (training dataset): \\n\", df_train_bert['label'].value_counts())\n",
    "print(\"\\n\")\n",
    "print(\"Unique labels in the dev dataset: \", df_dev_bert['label'].unique())\n",
    "print(\"Value counts by labels (dev dataset): \\n\", df_dev_bert['label'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>Bert Label</th>\n",
       "      <th>File Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>46098</td>\n",
       "      <td>0</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>602</td>\n",
       "      <td>1</td>\n",
       "      <td>after DCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1192</td>\n",
       "      <td>2</td>\n",
       "      <td>before DCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>680</td>\n",
       "      <td>3</td>\n",
       "      <td>during DCT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  Bert Label  File Label\n",
       "0  46098           0       Other\n",
       "1    602           1   after DCT\n",
       "2   1192           2  before DCT\n",
       "3    680           3  during DCT"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.DataFrame(df_train_bert['label'].value_counts(), index=None, columns=['label'])\n",
    "df2 = pd.DataFrame(df_train['label'].value_counts(), index=None, columns=['label'])\n",
    "df1['Bert Label'] = df1.index\n",
    "df1['File Label'] = df2.index\n",
    "\n",
    "df1.sort_values('Bert Label', inplace=True)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_write_path = 'data_for_bert_augmented/test_files_with_labels/'+tag.lower()+'_'+attribute[:3]\n",
    "# save the test file with labels for the purpose of running confusion matrix\n",
    "df_test.to_csv(test_write_path+'_testfile.csv')\n",
    "\n",
    "# save the label mappings between original test file and how it corresponds in BERT\n",
    "df1[['Bert Label', 'File Label']].to_csv(test_write_path+'_labelmapping.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the TRAINING & DEV data to folder\n",
    "\n",
    "Write the files into appropriate folders, so that it can be uploaded to cloud for processing / building model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_path = 'data_for_bert_augmented/'+tag.lower()+'_'+attribute[:3]\n",
    "\n",
    "# train / dev sets for TAG-ATTRIBUTE\n",
    "df_train_bert.to_csv(write_path+'/train.tsv', sep='\\t', index=False, header=False)\n",
    "df_dev_bert.to_csv(write_path+'/dev.tsv', sep='\\t', index=False, header=False)\n",
    "\n",
    "# test set for TAG-ATTRIBUTE\n",
    "df_test_bert.to_csv(write_path+'/test.tsv', sep='\\t', index=False, header=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check folder & Get Training\n",
    "\n",
    "The format of the datasets have been adjused so as to perform multi-class classification and predicted against the test dataset.  The dev set is used for calculating the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Other         34642\n",
       "during DCT      496\n",
       "before DCT      214\n",
       "after DCT       204\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1270</th>\n",
       "      <td>Diabetes (insulin-dependent, 3/66 HBA1C was 8.90)</td>\n",
       "      <td>before DCT</td>\n",
       "      <td>117-02.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1271</th>\n",
       "      <td>2.</td>\n",
       "      <td>Other</td>\n",
       "      <td>117-02.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1272</th>\n",
       "      <td>Hypercholesterolemia</td>\n",
       "      <td>Other</td>\n",
       "      <td>117-02.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1273</th>\n",
       "      <td>3.</td>\n",
       "      <td>Other</td>\n",
       "      <td>117-02.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1274</th>\n",
       "      <td>Hypertension</td>\n",
       "      <td>Other</td>\n",
       "      <td>117-02.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1275</th>\n",
       "      <td>4.</td>\n",
       "      <td>Other</td>\n",
       "      <td>117-02.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1276</th>\n",
       "      <td>History of angina</td>\n",
       "      <td>Other</td>\n",
       "      <td>117-02.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1277</th>\n",
       "      <td>5.</td>\n",
       "      <td>Other</td>\n",
       "      <td>117-02.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1278</th>\n",
       "      <td>History of cyst near scapular, upper left back</td>\n",
       "      <td>Other</td>\n",
       "      <td>117-02.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1279</th>\n",
       "      <td>6.</td>\n",
       "      <td>Other</td>\n",
       "      <td>117-02.xml</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence       label  \\\n",
       "1270  Diabetes (insulin-dependent, 3/66 HBA1C was 8.90)  before DCT   \n",
       "1271                                                 2.       Other   \n",
       "1272                               Hypercholesterolemia       Other   \n",
       "1273                                                 3.       Other   \n",
       "1274                                       Hypertension       Other   \n",
       "1275                                                 4.       Other   \n",
       "1276                                  History of angina       Other   \n",
       "1277                                                 5.       Other   \n",
       "1278     History of cyst near scapular, upper left back       Other   \n",
       "1279                                                 6.       Other   \n",
       "\n",
       "            file  \n",
       "1270  117-02.xml  \n",
       "1271  117-02.xml  \n",
       "1272  117-02.xml  \n",
       "1273  117-02.xml  \n",
       "1274  117-02.xml  \n",
       "1275  117-02.xml  \n",
       "1276  117-02.xml  \n",
       "1277  117-02.xml  \n",
       "1278  117-02.xml  \n",
       "1279  117-02.xml  "
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[1270:1280]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
