{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
     ]
    }
   ],
   "source": [
    "from flair.data import TaggedCorpus\n",
    "from flair.data_fetcher import NLPTaskDataFetcher, NLPTask\n",
    "from flair.embeddings import TokenEmbeddings, WordEmbeddings, StackedEmbeddings, FlairEmbeddings, BertEmbeddings, CharacterEmbeddings, DocumentRNNEmbeddings\n",
    "from flair.models import TextClassifier\n",
    "from flair.trainers import ModelTrainer\n",
    "from typing import List\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import xml.etree.cElementTree as ET\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import nltk.data\n",
    "from nltk import sent_tokenize\n",
    "from flair.data_fetcher import NLPTaskDataFetcher\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'10.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.version.cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7301"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.backends.cudnn.version()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GeForce GTX TITAN X'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flair Text Classification\n",
    "\n",
    "## Data Format\n",
    "```\n",
    "__label__<label_1> <text>\n",
    "__label__<label_1> __label__<label_2> <text>\n",
    "```\n",
    "\n",
    "The text classification data format is based on the `FastText format`, in which each line in the file represents a texxt document. A document can have one or multiple labels that are defined at the beginning of the line starting with the prefix `__label__`. \n",
    "\n",
    "To create a `TaggedCorpus` for a text classification task, you need to have three files (train, dev, and test) in the above format located in one folder. This data folder structure could, for example, look like this:\n",
    "\n",
    "```\n",
    "/resources/tasks/project/train.txt\n",
    "/resources/tasks/project/dev.txt\n",
    "/resources/tasks/imdb/test.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get files for parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['E:\\\\Google Drive\\\\Berkeley\\\\Courses\\\\w266_NLP\\\\Final Project\\\\data_all\\\\06_training-RiskFactors-Complete-Set1\\\\220-01.xml',\n",
       " 'E:\\\\Google Drive\\\\Berkeley\\\\Courses\\\\w266_NLP\\\\Final Project\\\\data_all\\\\06_training-RiskFactors-Complete-Set1\\\\220-02.xml',\n",
       " 'E:\\\\Google Drive\\\\Berkeley\\\\Courses\\\\w266_NLP\\\\Final Project\\\\data_all\\\\06_training-RiskFactors-Complete-Set1\\\\220-03.xml',\n",
       " 'E:\\\\Google Drive\\\\Berkeley\\\\Courses\\\\w266_NLP\\\\Final Project\\\\data_all\\\\06_training-RiskFactors-Complete-Set1\\\\220-04.xml',\n",
       " 'E:\\\\Google Drive\\\\Berkeley\\\\Courses\\\\w266_NLP\\\\Final Project\\\\data_all\\\\06_training-RiskFactors-Complete-Set1\\\\220-05.xml']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codefolder = os.path.dirname(os.path.abspath('__file__'))\n",
    "\n",
    "datafolders = ['\\\\data_all\\\\06_training-RiskFactors-Complete-Set1\\\\','\\\\data_all\\\\09_training-RiskFactors-Complete-Set2\\\\']\n",
    "filenames = []\n",
    "\n",
    "for folder in datafolders:\n",
    "    for file in os.listdir(str(codefolder)+folder):\n",
    "        filename=os.fsdecode(os.fsencode((str(codefolder)+folder+file)))\n",
    "        if filename.endswith(('.xml')):\n",
    "            filenames.append(filename)\n",
    "            \n",
    "filenames[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a 90/10 split\n",
    "split_index = int(len(filenames)*0.9)\n",
    "random.seed(42)\n",
    "random.shuffle(filenames)\n",
    "\n",
    "train_filenames = filenames[:split_index]\n",
    "dev_filenames = filenames[split_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafolder = '\\\\data_all\\\\16_testing-RiskFactors-Complete\\\\'\n",
    "test_filenames = []\n",
    "\n",
    "for file in os.listdir(str(codefolder)+datafolder):\n",
    "    filename=os.fsdecode(os.fsencode((str(codefolder)+datafolder+file)))\n",
    "    if filename.endswith(('.xml')):\n",
    "        test_filenames.append(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse sentences & labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentences(file):\n",
    "\n",
    "    tree = ET.ElementTree(file=file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    text = root.find('TEXT').text\n",
    "    sentences = [sent.split('\\n') for sent in sent_tokenize(text) if sent!='\\n']\n",
    "    all_sentences = []\n",
    "\n",
    "    for item in sentences:\n",
    "        for sub_item in item:\n",
    "            if sub_item.replace(' ','') != '':\n",
    "                all_sentences.append(sub_item)    \n",
    "    print(\"all_sentences:\",all_sentences[:5])\n",
    "    return all_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(file):\n",
    "    \n",
    "    # get all sentences in the file\n",
    "    tree = ET.ElementTree(file=file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    text = root.find('TEXT').text\n",
    "    sentences = [sent.split('\\n') for sent in sent_tokenize(text) if sent!='\\n']\n",
    "    all_sentences = []\n",
    "\n",
    "    for item in sentences:\n",
    "        for sub_item in item:\n",
    "            if sub_item.replace(' ','') != '':\n",
    "                all_sentences.append(sub_item)    \n",
    "                \n",
    "    #all_sent = get_sentences(file)\n",
    "    sent_label = {}\n",
    "\n",
    "    sub_tags = []\n",
    "    for item in root.find(\"TAGS\"):\n",
    "        if item.tag == 'PHI':\n",
    "            pass\n",
    "        elif item.tag == 'SMOKER':\n",
    "            label = (item.tag + \".\" + item.attrib['status']).lower().replace(\" \", \"_\")\n",
    "        elif item.tag == 'FAMILY_HIST':\n",
    "            label = (item.tag + \".\" + item.attrib['indicator']).lower().replace(\" \", \"_\")\n",
    "        elif item.tag == 'MEDICATION':\n",
    "            label = (item.tag + \".\" + item.attrib['type1'] + \".\" + item.attrib['type2'] + \".\" + item.attrib['time']).lower().replace(\" \", \"_\")\n",
    "        else:\n",
    "            label = (item.tag + \".\" + item.attrib['indicator'] + \".\" + item.attrib['time']).lower().replace(\" \", \"_\")\n",
    "        for sub_item in item.findall(item.tag):\n",
    "            #print(\"sub_item:\", sub_item.tag)\n",
    "            if ('text' in sub_item.attrib.keys()):\n",
    "                #print(sub_item.attrib['text'])\n",
    "                sub_tags.append((sub_item.attrib['text'], label))\n",
    "\n",
    "\n",
    "    count=0\n",
    "    for sent in all_sentences:\n",
    "        label='Other'\n",
    "        for tag in set(sub_tags):                                                       \n",
    "            if tag[0] in sent:\n",
    "                label = tag[1]\n",
    "                count += 1\n",
    "\n",
    "        sent_label[sent] = label\n",
    "        \n",
    "    # return empty dict if no tag found in file\n",
    "    # else, return the sentences with the labels\n",
    "    if count==0:\n",
    "        return {}\n",
    "    else:\n",
    "        #print(\"sent_label:\", sent_label)\n",
    "        return sent_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_TrainingData(filenames):\n",
    "    train_files = []\n",
    "    train_sent = []\n",
    "    train_labels = []\n",
    "    \n",
    "    train_df = pd.DataFrame()\n",
    "    for file in filenames:\n",
    "        file_data = process_file(file=file)\n",
    "        for i in range(0, len(file_data)):\n",
    "            train_files.append(file)\n",
    "            \n",
    "        for key, value in file_data.items():\n",
    "            train_sent.append(key)\n",
    "            train_labels.append(value)\n",
    "    \n",
    "    train_df = pd.DataFrame({'filename': train_files, 'sentence': train_sent, 'label': train_labels})\n",
    "    #print(train_df.head())\n",
    "    return train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = get_TrainingData(train_filenames)\n",
    "df_dev = get_TrainingData(dev_filenames)\n",
    "df_test = get_TrainingData(test_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['E:\\\\Google Drive\\\\Berkeley\\\\Courses\\\\w266_NLP\\\\Final Project\\\\data_all\\\\09_training-RiskFactors-Complete-Set2\\\\103-01.xml',\n",
       " 'E:\\\\Google Drive\\\\Berkeley\\\\Courses\\\\w266_NLP\\\\Final Project\\\\data_all\\\\09_training-RiskFactors-Complete-Set2\\\\109-02.xml',\n",
       " 'E:\\\\Google Drive\\\\Berkeley\\\\Courses\\\\w266_NLP\\\\Final Project\\\\data_all\\\\09_training-RiskFactors-Complete-Set2\\\\155-03.xml',\n",
       " 'E:\\\\Google Drive\\\\Berkeley\\\\Courses\\\\w266_NLP\\\\Final Project\\\\data_all\\\\06_training-RiskFactors-Complete-Set1\\\\251-03.xml',\n",
       " 'E:\\\\Google Drive\\\\Berkeley\\\\Courses\\\\w266_NLP\\\\Final Project\\\\data_all\\\\09_training-RiskFactors-Complete-Set2\\\\107-02.xml']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_filenames[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['E:\\\\Google Drive\\\\Berkeley\\\\Courses\\\\w266_NLP\\\\Final Project\\\\data_all\\\\06_training-RiskFactors-Complete-Set1\\\\335-03.xml',\n",
       " 'E:\\\\Google Drive\\\\Berkeley\\\\Courses\\\\w266_NLP\\\\Final Project\\\\data_all\\\\09_training-RiskFactors-Complete-Set2\\\\149-04.xml',\n",
       " 'E:\\\\Google Drive\\\\Berkeley\\\\Courses\\\\w266_NLP\\\\Final Project\\\\data_all\\\\06_training-RiskFactors-Complete-Set1\\\\366-04.xml',\n",
       " 'E:\\\\Google Drive\\\\Berkeley\\\\Courses\\\\w266_NLP\\\\Final Project\\\\data_all\\\\09_training-RiskFactors-Complete-Set2\\\\181-02.xml',\n",
       " 'E:\\\\Google Drive\\\\Berkeley\\\\Courses\\\\w266_NLP\\\\Final Project\\\\data_all\\\\09_training-RiskFactors-Complete-Set2\\\\180-01.xml']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_filenames[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['E:\\\\Google Drive\\\\Berkeley\\\\Courses\\\\w266_NLP\\\\Final Project\\\\data_all\\\\16_testing-RiskFactors-Complete\\\\110-01.xml',\n",
       " 'E:\\\\Google Drive\\\\Berkeley\\\\Courses\\\\w266_NLP\\\\Final Project\\\\data_all\\\\16_testing-RiskFactors-Complete\\\\110-02.xml',\n",
       " 'E:\\\\Google Drive\\\\Berkeley\\\\Courses\\\\w266_NLP\\\\Final Project\\\\data_all\\\\16_testing-RiskFactors-Complete\\\\110-03.xml',\n",
       " 'E:\\\\Google Drive\\\\Berkeley\\\\Courses\\\\w266_NLP\\\\Final Project\\\\data_all\\\\16_testing-RiskFactors-Complete\\\\110-04.xml',\n",
       " 'E:\\\\Google Drive\\\\Berkeley\\\\Courses\\\\w266_NLP\\\\Final Project\\\\data_all\\\\16_testing-RiskFactors-Complete\\\\111-01.xml']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_filenames[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E:\\Google Drive\\Berkeley\\Courses\\w266_NLP\\Fina...</td>\n",
       "      <td>Record date: 2067-11-24</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E:\\Google Drive\\Berkeley\\Courses\\w266_NLP\\Fina...</td>\n",
       "      <td>HUNTINGTON EMERGENCY DEPT...</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E:\\Google Drive\\Berkeley\\Courses\\w266_NLP\\Fina...</td>\n",
       "      <td>THOMAS-YOSEF,JULIA   840-91-51-9            VI...</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E:\\Google Drive\\Berkeley\\Courses\\w266_NLP\\Fina...</td>\n",
       "      <td>This patient was seen with Dr. Earley.</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E:\\Google Drive\\Berkeley\\Courses\\w266_NLP\\Fina...</td>\n",
       "      <td>The patient was interviewed</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filename  \\\n",
       "0  E:\\Google Drive\\Berkeley\\Courses\\w266_NLP\\Fina...   \n",
       "1  E:\\Google Drive\\Berkeley\\Courses\\w266_NLP\\Fina...   \n",
       "2  E:\\Google Drive\\Berkeley\\Courses\\w266_NLP\\Fina...   \n",
       "3  E:\\Google Drive\\Berkeley\\Courses\\w266_NLP\\Fina...   \n",
       "4  E:\\Google Drive\\Berkeley\\Courses\\w266_NLP\\Fina...   \n",
       "\n",
       "                                            sentence  label  \n",
       "0                            Record date: 2067-11-24  Other  \n",
       "1                       HUNTINGTON EMERGENCY DEPT...  Other  \n",
       "2  THOMAS-YOSEF,JULIA   840-91-51-9            VI...  Other  \n",
       "3             This patient was seen with Dr. Earley.  Other  \n",
       "4                       The patient was interviewed   Other  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E:\\Google Drive\\Berkeley\\Courses\\w266_NLP\\Fina...</td>\n",
       "      <td>Record date: 2104-01-30</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E:\\Google Drive\\Berkeley\\Courses\\w266_NLP\\Fina...</td>\n",
       "      <td>NEUROLOGY RESIDENT CONSULT NOTE</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E:\\Google Drive\\Berkeley\\Courses\\w266_NLP\\Fina...</td>\n",
       "      <td>PATIENT NAME: Dalila Haynes</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E:\\Google Drive\\Berkeley\\Courses\\w266_NLP\\Fina...</td>\n",
       "      <td>MRN: 78361343</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E:\\Google Drive\\Berkeley\\Courses\\w266_NLP\\Fina...</td>\n",
       "      <td>DATE OF CONSULT: 1/30/04</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filename  \\\n",
       "0  E:\\Google Drive\\Berkeley\\Courses\\w266_NLP\\Fina...   \n",
       "1  E:\\Google Drive\\Berkeley\\Courses\\w266_NLP\\Fina...   \n",
       "2  E:\\Google Drive\\Berkeley\\Courses\\w266_NLP\\Fina...   \n",
       "3  E:\\Google Drive\\Berkeley\\Courses\\w266_NLP\\Fina...   \n",
       "4  E:\\Google Drive\\Berkeley\\Courses\\w266_NLP\\Fina...   \n",
       "\n",
       "                           sentence  label  \n",
       "0           Record date: 2104-01-30  Other  \n",
       "1  NEUROLOGY RESIDENT CONSULT NOTE   Other  \n",
       "2       PATIENT NAME: Dalila Haynes  Other  \n",
       "3                     MRN: 78361343  Other  \n",
       "4          DATE OF CONSULT: 1/30/04  Other  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E:\\Google Drive\\Berkeley\\Courses\\w266_NLP\\Fina...</td>\n",
       "      <td>Record date: 2069-04-07</td>\n",
       "      <td>smoker.unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E:\\Google Drive\\Berkeley\\Courses\\w266_NLP\\Fina...</td>\n",
       "      <td>Mr. Villegas is seen today.</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E:\\Google Drive\\Berkeley\\Courses\\w266_NLP\\Fina...</td>\n",
       "      <td>I have not seen him since November.</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E:\\Google Drive\\Berkeley\\Courses\\w266_NLP\\Fina...</td>\n",
       "      <td>About three weeks ago he stopped his Prednison...</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E:\\Google Drive\\Berkeley\\Courses\\w266_NLP\\Fina...</td>\n",
       "      <td>he was gaining weight.</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filename  \\\n",
       "0  E:\\Google Drive\\Berkeley\\Courses\\w266_NLP\\Fina...   \n",
       "1  E:\\Google Drive\\Berkeley\\Courses\\w266_NLP\\Fina...   \n",
       "2  E:\\Google Drive\\Berkeley\\Courses\\w266_NLP\\Fina...   \n",
       "3  E:\\Google Drive\\Berkeley\\Courses\\w266_NLP\\Fina...   \n",
       "4  E:\\Google Drive\\Berkeley\\Courses\\w266_NLP\\Fina...   \n",
       "\n",
       "                                            sentence           label  \n",
       "0                            Record date: 2069-04-07  smoker.unknown  \n",
       "1                        Mr. Villegas is seen today.           Other  \n",
       "2                I have not seen him since November.           Other  \n",
       "3  About three weeks ago he stopped his Prednison...           Other  \n",
       "4                             he was gaining weight.           Other  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0               __label__Other Record date: 2067-11-24\n",
       "1    __label__Other                      HUNTINGTON...\n",
       "2    __label__Other THOMAS-YOSEF,JULIA   840-91-51-...\n",
       "3    __label__Other This patient was seen with Dr. ...\n",
       "4          __label__Other The patient was interviewed \n",
       "Name: formatted, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_flair = df_train[['label', 'sentence']].copy()\n",
    "df_train_flair['prefix'] = '__label__'\n",
    "df_train_flair = df_train_flair[['prefix', 'label', 'sentence']]\n",
    "df_train_flair['formatted'] = df_train_flair['prefix']+df_train_flair['label']+' '+df_train_flair['sentence']\n",
    "df_train_flair['formatted'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0             __label__Other Record date: 2104-01-30\n",
       "1    __label__Other NEUROLOGY RESIDENT CONSULT NOTE \n",
       "2         __label__Other PATIENT NAME: Dalila Haynes\n",
       "3                       __label__Other MRN: 78361343\n",
       "4            __label__Other DATE OF CONSULT: 1/30/04\n",
       "Name: formatted, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev_flair = df_dev[['label', 'sentence']].copy()\n",
    "df_dev_flair['prefix'] = '__label__'\n",
    "df_dev_flair = df_dev_flair[['prefix', 'label', 'sentence']]\n",
    "df_dev_flair['formatted'] = df_dev_flair['prefix']+df_dev_flair['label']+' '+df_dev_flair['sentence']\n",
    "df_dev_flair['formatted'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      __label__smoker.unknown Record date: 2069-04-07\n",
       "1           __label__Other Mr. Villegas is seen today.\n",
       "2    __label__Other I have not seen him since Novem...\n",
       "3    __label__Other About three weeks ago he stoppe...\n",
       "4                __label__Other he was gaining weight.\n",
       "Name: formatted, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_flair = df_test[['label', 'sentence']].copy()\n",
    "df_test_flair['prefix'] = '__label__'\n",
    "df_test_flair = df_test_flair[['prefix', 'label', 'sentence']]\n",
    "df_test_flair['formatted'] = df_test_flair['prefix']+df_test_flair['label']+' '+df_test_flair['sentence']\n",
    "df_test_flair['formatted'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_flair['formatted'].to_csv('E:\\\\Google Drive\\\\Berkeley\\\\Courses\\\\w266_NLP\\\\Final Project\\\\FLAIR_data\\\\train.txt', index=False, header=False)\n",
    "df_dev_flair['formatted'].to_csv('E:\\\\Google Drive\\\\Berkeley\\\\Courses\\\\w266_NLP\\\\Final Project\\\\FLAIR_data\\\\dev.txt', index=False, header=False)\n",
    "df_test_flair['formatted'].to_csv('E:\\\\Google Drive\\\\Berkeley\\\\Courses\\\\w266_NLP\\\\Final Project\\\\FLAIR_data\\\\test.txt', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-04-11 19:46:30,433 Reading data from E:\\Google Drive\\Berkeley\\Courses\\w266_NLP\\Final Project\\FLAIR_data\n",
      "2019-04-11 19:46:30,434 Train: E:\\Google Drive\\Berkeley\\Courses\\w266_NLP\\Final Project\\FLAIR_data\\train.txt\n",
      "2019-04-11 19:46:30,436 Dev: E:\\Google Drive\\Berkeley\\Courses\\w266_NLP\\Final Project\\FLAIR_data\\dev.txt\n",
      "2019-04-11 19:46:30,437 Test: E:\\Google Drive\\Berkeley\\Courses\\w266_NLP\\Final Project\\FLAIR_data\\test.txt\n"
     ]
    }
   ],
   "source": [
    "data_folder = Path('E:\\\\Google Drive\\\\Berkeley\\\\Courses\\\\w266_NLP\\\\Final Project\\\\FLAIR_data\\\\')\n",
    "\n",
    "# load corpus containing training, test, and dev data\n",
    "corpus: TaggedCorpus = NLPTaskDataFetcher.load_classification_corpus(data_folder,\n",
    "                                                                     test_file='test.txt',\n",
    "                                                                     dev_file='dev.txt',\n",
    "                                                                     train_file='train.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create label dictionary\n",
    "label_dict = corpus.make_label_dictionary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize embeddings to stack later\n",
    "#bert_embedding = BertEmbeddings()\n",
    "#char_embedding = CharacterEmbeddings()\n",
    "flair_embedding_forward = FlairEmbeddings('pubmed-forward')\n",
    "flair_embedding_backward = FlairEmbeddings('pubmed-backward')\n",
    "\n",
    "# create StackedEmbedding object\n",
    "stacked_embeddings = StackedEmbeddings(embeddings=[flair_embedding_forward, flair_embedding_backward])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize document embedding by passing list of word embeddings\n",
    "document_embeddings: DocumentRNNEmbeddings = DocumentRNNEmbeddings(stacked_embeddings,\n",
    "                                                                     hidden_size=512,\n",
    "                                                                     reproject_words=True,\n",
    "                                                                     reproject_words_dimension=256,\n",
    "                                                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create text classifier\n",
    "classifier = TextClassifier(document_embeddings, label_dictionary=label_dict, multi_label=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the text classifier trainer\n",
    "trainer = ModelTrainer(classifier, corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-04-11 19:47:07,023 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-11 19:47:07,025 Evaluation method: MICRO_F1_SCORE\n",
      "2019-04-11 19:47:07,040 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-11 19:47:08,914 epoch 1 - iter 0/3115 - loss 0.28503412\n"
     ]
    }
   ],
   "source": [
    "trainer.train('E:\\\\Google Drive\\\\Berkeley\\\\Courses\\\\w266_NLP\\\\Final Project\\\\FLAIR_data\\\\BERT',\n",
    "              learning_rate=0.1,\n",
    "              mini_batch_size=16,\n",
    "              anneal_factor=0.5,\n",
    "              patience=5,\n",
    "              max_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
